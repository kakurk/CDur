---
title: "Memory Cue Duration and Directed Forgetting"
author: "Kyle Kurkela and Nancy Dennis"
date: '`r Sys.Date()`'
output: 
  html_document: 
    code_folding: hide
    toc: yes
    toc_float: yes
params:
  rootpath: ~/Documents/MATLAB/githubrepos/personal-repos/CDur
---

```{r echo=FALSE}
options(scipen = 10, digits = 4)
options(knitr.kable.NA = '')
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
```

# Loading Libraries

For the purposes of this notebook, I will be using the `tidyverse` and `knitr` packages.


```{r libraries}
library('tidyverse')
library('knitr')
library('emmeans')
library('kableExtra')
library('magrittr')
library('afex')
library('ez')
library('gghighlight')
```

# Load Data

Load the raw data into R from the `datapath` directory input at the top of the notebook.  

```{r load}
# Initialize variables
ya_raw_data_file   <- file.path('data', "ya_raw_data.csv")
oa_raw_data_file   <- file.path('data', "oa_raw_data.csv")
demo_raw_data_file <- file.path('data', "demographics.csv")

# Load data into data frames
df.young        <- read.csv(ya_raw_data_file, quote = "\'")
df.old          <- read.csv(oa_raw_data_file, quote = "\'")
df.demographics <- read.csv(demo_raw_data_file, quote = "\'")

# Remove problem subjects o322, o122, and o307
df.old          <- filter(df.old, subject != 'o322')
df.old          <- filter(df.old, subject != 'o122')
df.old          <- filter(df.old, subject != 'o307')

df.demographics <- filter(df.demographics, SUBJECT != 'o322')
df.demographics <- filter(df.demographics, SUBJECT != 'o122')
df.demographics <- filter(df.demographics, SUBJECT != 'o307')
```

# Data Cleaning

## Demographics

In this section of the notebook, we will be cleaning up the demographics data by:  

1. Dropping empty variables.  
2. Creating the `EDUCATION_yrs` variable, which calculates the `EDUCATION` variable in terms of years of schooling.  
3. Forcing the `AGE` and `SEX` variables to follow the all capitalization variable naming convention of this notebook.  
4. Compute the composite `BASELINE_COGITIVE_ABILITY` variable by calculating the mean (rounded to 2 decimal points) of the each subject's Symbol Search, Digit-Symbol, Arithmetic, Letter-Number Sequencing, and Vocabulary scores. 

```{r clean_demographics_data}
# dropping blank variables; creating EDUCTION_yrs
df.demographics %>%
  select(-X, -X.1) %>%
  mutate(EDUCATION_yrs = ifelse(EDUCATION == '8th grade', 8,
                         ifelse(EDUCATION == '9th grade', 9, 
                         ifelse(EDUCATION == '10th grade', 10,
                         ifelse(EDUCATION == '11th grade', 11,
                         ifelse(EDUCATION == '12th grade', 12,
                         ifelse(EDUCATION == '1 yr college' | 
                                EDUCATION == '1 Year college' | 
                                EDUCATION == '1 year college', 13,
                         ifelse(EDUCATION == '2 yrs college' | 
                                EDUCATION == '2 Years college' | 
                                EDUCATION == '2 years college', 14,
                         ifelse(EDUCATION == '3 yrs college' | 
                                EDUCATION == '3 Years college' | 
                                EDUCATION == '3 years college', 15,
                         ifelse(EDUCATION == '4 yrs college' | 
                                EDUCATION == '4 Years college' | 
                                EDUCATION == '4 years college', 16,
                         ifelse(EDUCATION == 'Post-grad work', 17,
                         ifelse(EDUCATION == 'Masters', 18,
                         ifelse(EDUCATION == 'Doctoral', 20, NA)))))))))))),
         Sex = ifelse(Sex == 'F', 'Female', 
               ifelse(Sex == 'M', 'Male', NA))) -> df.demographics 

# Force Age and Sex variables into the all capitalization variable name convention
colnames(df.demographics)[10:11] <- c("AGE", "SEX")

# Calculating Cognitive Assessment Composite Score
CogAssessMeasures <- c('SYMBOLSEARCH', 'DIGITSYMBOL', 'DIGITSPAN', 'ARITHMETIC', 'LNSEQUENCING', 'VOCAB')
df.demographics %>%
  rowwise() %>%
  mutate(BASELINE_COGITIVE_ABILITY = mean(c_across(all_of(CogAssessMeasures)), na.rm = T),
         BASELINE_COGITIVE_ABILITY = round(BASELINE_COGITIVE_ABILITY, digits = 2)) %>%
  ungroup() -> df.demographics

# Calculate the Composite Z score
df.demographics %>%
  mutate(AgeGroup = str_extract(string = SUBJECT, pattern = '^[yo]'),
         AgeGroup = factor(AgeGroup, 
                           levels = c('y', 'o'), 
                           labels = c('Young Adults', 'Old Adults'))) %>%
  group_by(AgeGroup) %>%
  mutate(across(all_of(CogAssessMeasures), scale)) %>%
  ungroup() %>%
  rowwise() %>%
  mutate(COMPOSITEZSCORE = mean(c_across(all_of(CogAssessMeasures)), na.rm = T)) -> df.demographics.z
```

## Raw Experimental Data

In this section of the notebook we will be cleaning the raw experimental data by:  

1. Concatenating the young and old data and creating a new variable `AgeGroup`.    
2. Dropping the extra jitter variable.  
3. Making the numeric coding of variables `enctype`, `score`, `Response`, `type`, and `AgeGroup` into factors with informative level names.  

```{r concatenate_and_clean}
# concatenate
df.all <- bind_rows(list(df.young, df.old), .id = "AgeGroup")

# clean
df.all %>%
  select(-jit.1) %>% # dropping extra jitter
  mutate(
    enctype  = ifelse(enctype == 1, '1 Second',
               ifelse(enctype == 3, '3 Seconds', 
               ifelse(enctype == 5, '5 Seconds', 'Lure'))),
    enctype  = factor(enctype),
    score    = ifelse(score == 1, 'Remember',
               ifelse(score == 2, 'Know',
               ifelse(score == 3, 'New', 'No Response'))),
    score    = factor(score),
    Response = ifelse(Response == 2, 'B Key',
               ifelse(Response == 22, 'V Key',
               ifelse(Response == 14, 'N Key', 'No Response'))),
    Response = factor(Response),
    type     = ifelse(type == 0, 'To Be Forgotten', 
               ifelse(type == 1, 'To Be Remembered', 'Lure')),
    type     = factor(type),
    AgeGroup = ifelse(AgeGroup == 1, 'Young', 
               ifelse(AgeGroup == 2, 'Old', NA)),
    AgeGroup = factor(AgeGroup)
  ) -> df.all
```

# Table 1: Demographics Summary

```{r demographics_summary}

# take the demographics data frame and tidy it
df.demographics %>%
  mutate(AgeGroup = str_extract(SUBJECT, '^[oy]'),
         AgeGroup = factor(AgeGroup, 
                           levels = c('y', 'o'), 
                           labels = c('Younger Adults', 'Old Adults'))) %>%
  select(-SUBJECT) -> df.demographics.tidy

df.demographics.tidy %>%
  group_by(AgeGroup) %>%
  summarise(across(where(is.numeric), list(mean = mean, sd = sd), na.rm = T)) %>%
  mutate(across(where(is.numeric), round, digits = 2)) %>%
  pivot_longer(names_to='Measure', values_to = 'value', -AgeGroup, values_drop_na = T) %>%
  separate(col = Measure, sep = '_(?=(sd)|(mean))', into = c('Measure', 'statistic')) %>% 
  pivot_wider(names_from = statistic, values_from = value) %>%
  mutate(cellvalue = str_c(mean, ' (', sd, ')')) %>% 
  select(-mean, -sd) %>%
  pivot_wider(names_from = 'AgeGroup', values_from = 'cellvalue') %>% 
  mutate(Measure = recode(Measure, 
                          'EDUCATION_yrs' = 'EDUCATION',
                          'BASELINE_COGITIVE_ABILITY' = 'COMPOSITE')) -> table1.demographics

df.demographics.tidy %>%
  mutate_at('SEX', ~recode(.x, 'Female' = 1, 'Male' = 0)) %>%
  rename('FEMALE' = 'SEX') %>%
  group_by(AgeGroup) %>%
  summarise(across(FEMALE, sum)) %>%
  pivot_longer(FEMALE, names_to = 'Measure', values_to = 'cellvalue') %>%
  mutate_at('cellvalue', as.character) %>%
  pivot_wider(names_from = AgeGroup, values_from = cellvalue) -> FEMALE

df.demographics.tidy %>%
  group_by(AgeGroup) %>%
  summarise(N = n()) %>%
  pivot_longer(N, names_to = 'Measure', values_to = 'cellvalue') %>%
  mutate_at('cellvalue', as.character) %>%
  pivot_wider(names_from = AgeGroup, values_from = cellvalue) -> NN
  
# Display the Table
bind_rows(table1.demographics, FEMALE, NN) %>%
  slice(c(12,7,11,8,10,1:6,9)) %>%
  mutate(`Younger Adults` = if_else(is.na(`Younger Adults`), 
                                    str_c('NA', footnote_marker_alphabet(1)), 
                                    as.character(`Younger Adults`))) -> table1.demographics

names(table1.demographics)[2] <- str_c(names(table1.demographics)[2], footnote_marker_symbol(1))

table1.demographics %>%
  kable(format = 'html', 
        booktabs = T,
        escape = F, 
        caption = 'Table 1: Participant Demographics') %>%
  kable_styling() %>%
  footnote(general_title ='\n\nTable 1. ',
           general = 'mean (sd). N = size of sample, AGE = age in years , FEMALE = number of female participants, EDUCATION = years of education. See text for description of the cognitive assessment measures and the calculation of the composite score.\n\n', 
           symbol = 'Two younger adults did not complete the cognitive assessment battery. Means and standard deviations based on the Cognitive Assessment battery reflect 28 complete datasets.',
           alphabet = 'Younger adults were not required to complete the MMSE as part of the cognitive assessment battery.',
           footnote_as_chunk = T, 
           title_format = 'bold')
```

# DF-Effect

The first question we want to answer statistically: Do we see the `Directed-Forgetting Effect` in ANY of our experimental conditions?

First, lets calculate the `Directed-Forgetting Effect`:  

$$DF_{Effect} = p(New|TBF) - p(New|TBR)$$

where:  
- New = "New" response during the recognition memory test  
- TBF = Old Image that received a "To Be Forgotten" instruction during encoding  
- TBR = Old Image that received a "To Be Remembered" instruction during encoding  

```{r DF_calculations}
# Calculate the miss rates
df.all %>%
  filter(enctype != "Lure") %>%
  mutate(enctype = factor(enctype)) %>%
  group_by(AgeGroup, enctype, type, subject) %>%
  summarize(MissRate = mean(score == "New")) %>% ungroup() -> df.missrates

# Break the dataframe into TBF and TBR trials
df.missrates %>% filter(type == "To Be Forgotten") %>% select(-type) -> TBF.Forgotten
df.missrates %>% filter(type == "To Be Remembered") %>% select(-type) -> TBR.Forgotten

# Merge join the TBF and TBR data frames together, making a "wide" dataframe
df.DFeffects <- left_join(TBF.Forgotten, TBR.Forgotten, 
                          by = c('AgeGroup','enctype', 'subject'), 
                          suffix = c("TBF", "TBR"))

# Calculate the DF-Effect
df.DFeffects %>%
  transmute(
    AgeGroup = AgeGroup,
    enctype = enctype,
    subject = subject,
    DF.effect = MissRateTBF - MissRateTBR) -> df.DFeffects
```

## Figure 1: Directed Forgetting Results

```{r}
# A Visual
df.DFeffects %>%
  ggplot(aes(x = AgeGroup, y = DF.effect, group = enctype, fill = enctype)) + 
  stat_summary(geom = 'bar', fun.data = mean_se, position = position_dodge(width = .95)) + 
  stat_summary(geom = 'errorbar', fun.data = mean_se, width = 0.2, position = position_dodge(width = .95)) + 
  scale_fill_brewer(palette = "Set2") + 
  scale_y_continuous(expand = c(0, 0, .05, 0)) + 
  ggtitle("Directed Forgetting Effect") + 
  ylab("DF Effect") + 
  xlab("Age Group") + 
  labs(fill = 'Cue Duration') +
  theme(plot.title = element_text(hjust = 0.5), 
        axis.ticks.x = element_blank(), 
        axis.text.x = element_text(size = 12)) -> p

p
```

```{r, echo=FALSE}
ggsave(file.path(rootpath, 'figures', 'Figure3.png'), 
      dpi = 300, 
      width = 7,
      height = 5,
      units = 'in')
```

Check to see that both age groups showed an statistically significant DF-effect:

```{r}
# average over the cue duration conditions
# run a one-sample t-test separately for OAs and YAs 

ttest_and_tidy <- function(dataframe){
  test_result <- t.test(x = dataframe$DF.effect, mu = 0, alternative = 'greater')
  test_result_tidy <- broom::tidy(test_result)
  return(test_result_tidy)
}

df.DFeffects %>% 
  group_by(AgeGroup, subject) %>% 
  summarise(DF.effect = mean(DF.effect)) %>% 
  nest() %>% 
  mutate(TESTRES = map(data, ttest_and_tidy)) %>% 
  unnest(TESTRES) %>% 
  select(-data)
```

Bonferroni corrected t-tests of each experimental group against zero:

```{r}
ttest_and_tidy <- function(dataframe){
  test_result <- t.test(x = dataframe$DF.effect, mu = 0, alternative = 'greater')
  test_result_tidy <- broom::tidy(test_result)
  return(test_result_tidy)
}

df.DFeffects %>%
  group_by(AgeGroup, enctype) %>%
  nest() %>%
  mutate(TESTRES = map(data, ttest_and_tidy)) %>%
  unnest(TESTRES) %>%
  select(-data) %>%
  # bonferroni corrected p values
  mutate(p.value = p.adjust(p.value, method = 'bonferroni'))
```

The **Age Group x Cue Duration ANOVA** table:  

```{r ANOVA}
# using polynomial contrast effects coding
contrasts(df.DFeffects$enctype) <- contr.poly(3)

# ANOVA
ANOVA <- aov(DF.effect ~ AgeGroup * enctype + Error(subject/enctype), data = df.DFeffects)
 
summary(ANOVA, split = list(enctype = list(Linear = 1, Quad = 2)), expand.split = T)
```

Testing the linear and quadratic trends within each Age Group:

```{r}
# using polynomial contrast effects coding
contrasts(df.DFeffects$enctype) <- contr.poly(3)

ANOVA <- aov(DF.effect ~ enctype + Error(subject/enctype), data = df.DFeffects, subset = df.DFeffects$AgeGroup == 'Old')
 
summary(ANOVA, split = list(enctype = list(Linear = 1, Quad = 2)), expand.split = T)
```

```{r}
# using a "pleatau" effect coding
contrasts(df.DFeffects$enctype) <- matrix(c(-1, .5, .5, 0, 1, -1), nrow = 3)

ANOVA <- aov(DF.effect ~ enctype + Error(subject/enctype), data = df.DFeffects, subset = df.DFeffects$AgeGroup == 'Young')
 
summary(ANOVA, split = list(enctype = list(Pleatau = 1, ThreeVFive = 2)), expand.split = T)
```

```{r}
df.DFeffects %>%
  mutate(enctype.L = recode(enctype,
                            `1 Second` = -1,
                            `3 Seconds` = 0,
                            `5 Seconds` = 1),
         enctype.P = recode(enctype,
                            `1 Second` = -1,
                            `3 Seconds` = .5,
                            `5 Seconds` = .5)) -> DATA

Linear.Model  <- lm(DF.effect ~ enctype.L, data = DATA, subset = DATA$AgeGroup == 'Young')
Pleatau.Model <- lm(DF.effect ~ enctype.P, data = DATA, subset = DATA$AgeGroup == 'Young')

bind_rows(broom::glance(Linear.Model), broom::glance(Pleatau.Model), .id = 'model') %>%
  mutate(model = factor(model, levels = c(1,2), labels = c('Linear', 'Pleatau'))) %>%
  select(model, r.squared, AIC, everything())
```

```{r}
df.DFeffects %>%
  mutate(enctype.L = recode(enctype, 
                            `1 Second` = -1,
                            `3 Seconds` = 0,
                            `5 Seconds` = 1),
         enctype.P = recode(enctype, 
                            `1 Second` = -1,
                            `3 Seconds` = .5,
                            `5 Seconds` = .5)) -> DATA

Linear.Model  <- lm(DF.effect ~ enctype.L, data = DATA, subset = DATA$AgeGroup == 'Old')
Pleatau.Model <- lm(DF.effect ~ enctype.P, data = DATA, subset = DATA$AgeGroup == 'Old')

bind_rows(broom::glance(Linear.Model), broom::glance(Pleatau.Model), .id = 'model') %>%
  mutate(model = factor(model, levels = c(1,2), labels = c('Linear', 'Pleatau'))) %>%
  select(model, r.squared, AIC, everything())
```

## Figure 2: Directed Forgetting and Cog Assess Composite

What do our results look like when we consider baseline cognitive assessment score?

```{r Visual}
cog.assess.composites <- select(df.demographics.z, SUBJECT, COMPOSITEZSCORE)
cog.assess.composites <- transmute(cog.assess.composites, subject = SUBJECT, 
                                   composite = COMPOSITEZSCORE)

df.DFeffects <- left_join(df.DFeffects, cog.assess.composites, by = "subject")

df.DFeffects %>% 
  filter(AgeGroup == 'Old') %>%
  ggplot(aes(y = DF.effect, x = composite, colour = AgeGroup)) + 
    scale_colour_brewer(palette = "Set2", guide = FALSE) + 
    geom_point() + 
    facet_grid(. ~ enctype) + 
    geom_smooth(method = "lm", 
                formula = y ~ x, 
                se = TRUE, 
                colour = "navyblue", 
                linetype = "longdash") +
  labs(y = 'DF-Effect',
       x = 'Composite Cognitive Assessment Score',
       title = 'Individual Differences Among Older Adults',
       subtitle = 'Directed Forgetting Effect')
```

```{r, echo=FALSE}
ggsave(file.path(rootpath, 'figures', 'Figure5.png'), 
      dpi = 300, 
      width = 7,
      height = 5,
      units = 'in')
```

ANCOVA of DF.effect on Cue Duration and Composite Cog Assess Score within OAs only:  

```{r}
# Is there an interaction between Age Group and Composite Cog Assess score?
OAonly.df <- df.DFeffects %>% filter(AgeGroup == 'Old')

contrasts(OAonly.df$enctype) <- matrix(c(-.5, -.5, 1, 1, -1, 0), nrow = 3)

ANCOVA <- aov(DF.effect ~ enctype*composite + Error(subject/enctype),
              data = OAonly.df)

summary(ANCOVA, split = list(enctype = list(Five_v_OneThree = 1, One_v_Three = 2)))
```

# Rec Effect

A second question we would like to answer is this: is there a significant `Recollection Effect`? The Recollection Effects operationalized as:  

$$Rec_{Effect} = p(R|TBR) - p(R|TBF)$$

where:
- R = trials where a recognition probe recieved a "Remember" response in Remember/Know/New recognition.  
- TBR = recognition probes that were previously studied with a To Be Remembered instruction  
- TBF = recognition probes that were previously studied with a To Be Forgotten instruction  

This measure is similar too, but different than, the DF-Effect.  

First, lets calculate the recollection effects:  

```{r rec-effect_calculations}
# calculate the Rec rates
df.all %>%
  filter(enctype != "Lure") %>%
  mutate(enctype = factor(enctype)) %>%
  group_by(AgeGroup, enctype, type, subject) %>%
  summarize(RecRate = mean(score == "Remember")) %>% ungroup() -> df.recrates

# Break the dataframe into TBF and TBR
df.recrates %>% filter(type == "To Be Forgotten") %>% select(-type)  -> TBF.Remembered
df.recrates %>% filter(type == "To Be Remembered") %>% select(-type) -> TBR.Remembered

# Merge join the TBF and TBR data frames together, making a "wide" dataframe
df.RecEffects <- left_join(TBF.Remembered, TBR.Remembered, 
                           by = c('AgeGroup','enctype', 'subject'), 
                           suffix = c("TBF", "TBR"))

# Calculate the Rec-Effect
df.RecEffects %>%
  transmute(
    AgeGroup = AgeGroup,
    enctype = enctype,
    subject = subject,
    Rec.effect = RecRateTBR - RecRateTBF) -> df.RecEffects
```

## By Condition By Age Group

A visual of the results:  

```{r}
# A Visual
df.RecEffects %>%
  ggplot(aes(x = AgeGroup, y = Rec.effect, fill = enctype)) + 
  stat_summary(geom = 'bar', fun.data = mean_se, position = position_dodge(width = .95)) + 
  stat_summary(geom = 'errorbar', fun.data = mean_se, width = 0.2, position = position_dodge(width = .95)) + 
  scale_fill_brewer(palette = "Set2") + 
  scale_y_continuous(expand = c(0, 0, .05, 0)) + 
  ggtitle("Recollection Effect") + 
  ylab("Rec-Effect") + xlab("Age Group") + 
  labs(fill = 'Cue Duration') +
  theme(plot.title = element_text(hjust = 0.5), 
        axis.ticks.x = element_blank(), 
        axis.text.x = element_text(size = 12))
```

```{r, echo=FALSE}
ggsave(file.path(rootpath, 'figures', 'Figure4.png'), 
      dpi = 300, 
      width = 7,
      height = 5,
      units = 'in')
```

The **Age Group x Cue Duration ANOVA** table:  

```{r}
# polynomical effects contrast coding
contrasts(df.RecEffects$enctype) <- contr.poly(n = 3)

# ANOVA
ANOVA <- aov(Rec.effect ~ AgeGroup * enctype + Error(subject/enctype), data = df.RecEffects)

# Summarize, break into between and repeated factors
summary(ANOVA, split = list(enctype = list(Linear = 1, Quad = 2)), expand.split = FALSE)
```

Separate one sample t-tests for each age group greater than zero:  

```{r paged.print=TRUE}
ttest_and_tidy <- function(dataframe){
  # run a one sample t-test and tidy up the results
  test_result <- t.test(x = dataframe$Rec.effect, mu = 0, alternative = 'greater')
  test_result_tidy <- broom::tidy(test_result)
  return(test_result_tidy)
}

df.RecEffects %>%
  group_by(AgeGroup, subject) %>%
  summarise(Rec.effect = mean(Rec.effect)) %>%
  nest() %>%
  mutate(TESTRES = map(data, ttest_and_tidy)) %>%
  unnest(TESTRES) %>%
  select(-data)
```

```{r}
ttest_and_tidy <- function(dataframe){
  # run a one sample t-test and tidy up the results
  test_result <- t.test(x = dataframe$Rec.effect, mu = 0, alternative = 'greater')
  test_result_tidy <- broom::tidy(test_result)
  return(test_result_tidy)
}

df.RecEffects %>%
  group_by(AgeGroup, enctype) %>%
  nest() %>%
  mutate(TESTRES = map(data, ttest_and_tidy)) %>%
  unnest(TESTRES) %>%
  select(-data) %>%
  # bonferroni correction
  mutate(p.value = p.adjust(p.value, method = 'bonferroni'))
```

# Correlation Amongst Measures

Correlation Matrix between all of the cognitive assessment tasks for Older Adults.  

```{r}
# calculate correlation matrix
df.DFeffects %>%
  group_by(AgeGroup, subject) %>%
  summarise(across(DF.effect, mean)) %>%
  filter(AgeGroup == 'Old') -> Mean.OA.DF.Effects

df.demographics %>%
  left_join(Mean.OA.DF.Effects, by = c('SUBJECT' = 'subject')) %>%
  filter(AGE > 60) -> OA.Only.Demo.Df

order <- c('SYMBOLSEARCH', 'DIGITSYMBOL', 'DIGITSPAN', 'ARITHMETIC', 'LNSEQUENCING', 'VOCAB', 'MMSE')

OA.Only.Demo.Df %>%
  select(MMSE:VOCAB) %>%
  corrr::correlate(quiet = T) -> CorMat.df
```

```{r}
# reorganize and pretty print
CorMat.df %>%
  select(rowname, all_of(order)) %>%
  column_to_rownames() %>%
  magrittr::extract(order,order) %>%
  rownames_to_column() %>%
  corrr::fashion()
```


```{r}
# correlation matrix visual
CorMat.df %>%
  corrr::stretch() %>%
  ggplot(aes(x,y,fill = r)) +
  geom_raster() +
  scale_fill_distiller(palette = 'YlOrRd') +
  scale_x_discrete(limits = order) +
  scale_y_discrete(limits = rev(order)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme(axis.title = element_blank()) +
  theme(axis.ticks = element_blank()) +
  theme(panel.grid = element_blank()) +
  theme(panel.background = element_blank()) +
  labs(title = 'Composite Score Correlation Matrix',
       subtitle = 'Older Adults')
```

# False Alarm Rates

```{r}
# Calculate False Alarm Rates
df.all %>%
  filter(enctype == "Lure") %>%
  mutate(enctype = factor(enctype)) %>%
  group_by(AgeGroup, enctype, type, subject) %>%
  summarize(FARate = mean(score == "Know" | score == 'Remember')) %>% ungroup() -> df.FArates
```

```{r}
t.test(FARate ~ AgeGroup, data = df.FArates, var.equal = T)
```

# Full Design Analyses

What is driving the DF-effect?

```{r, warning = FALSE, message = FALSE}
df.all %>%
  # drop lures
  filter(enctype != 'Lure') %>%
  mutate(type = fct_drop(type),
         enctype = fct_drop(enctype)) %>%
  count(AgeGroup, subject, type, enctype, score) %>%
  complete(nesting(AgeGroup, subject), type, enctype, score, fill = list(n = 0)) -> PivotTable

PivotTable
```

+ `AgeGroup` = self-explanatory  
+ `subject` = subject identifier  
+ `type` = TBR/TBF  
+ `enctype` = Cue Duration  
+ `score` = Subject's Response Category  
+ `n` = number of trials  

```{r}
# raw data after Kyle's hand-spun tidying (see code above)
head(df.all)
```

```{r}
df.all %>%
  # drop lures
  filter(enctype != 'Lure') %>%
  mutate(type = fct_drop(type),
         enctype = fct_drop(enctype)) %>%
  count(AgeGroup, subject, type, enctype, score) %>%
  complete(nesting(AgeGroup, subject), type, enctype, score, fill = list(n = 0)) -> PivotTable

head(PivotTable)
```

```{r, warning=FALSE, message=FALSE}
PivotTable %>% 
  # calculate rate -- number of trials / total per condition
  group_by(AgeGroup, subject, enctype, type) %>% 
  mutate(total = sum(n), rate = n / total) %>% 
  # find the mean, sem across 30 subjects for each condition
  ungroup() %>% 
  group_by(AgeGroup, type, enctype, score) %>% 
  summarise(avg.rate = mean(rate), se.rate = std(rate), .groups = 'drop') %>%
  # remove NR trials
  filter(score != 'No Response') %>%
  # tidyverse tables are 'long'. In this chunk I am making the table 'wide'
  unite(col = 'CueDurxCueType', type, enctype, sep = '-') %>% 
  mutate(mean_se = str_c(round(avg.rate, 2), ' (', round(se.rate, 2), ')')) %>% 
  select(-avg.rate, -se.rate) %>%
  mutate(CueDurxCueType = factor(CueDurxCueType, levels = c('To Be Remembered-1 Second', 'To Be Remembered-3 Seconds', 
                                                            'To Be Remembered-5 Seconds', 'To Be Forgotten-1 Second', 
                                                            'To Be Forgotten-3 Seconds', 'To Be Forgotten-5 Seconds'))) %>%
  arrange(AgeGroup, CueDurxCueType, score) %>%
  pivot_wider(names_from = CueDurxCueType, values_from = mean_se) -> RateTbl

RateTbl %>%
  mutate(score = fct_drop(score)) %>%
  mutate(score = fct_relevel(score, c('Remember', 'Know', 'New'))) %>%
  mutate(AgeGroup = fct_relevel(AgeGroup, c('Young', 'Old'))) %>%
  arrange(AgeGroup, score) %>%
  kable(col.names = c('Age Group', '', '1 sec', '3 sec', '5 sec', '1 sec', '3 sec', '5 sec')) %>%
  kable_classic() %>%
  add_header_above(c('', '', 'TBR' = 3, 'TBF' = 3)) %>%
  collapse_rows(columns = 1, valign = "top") %>%
  footnote(general = 'Mean (SE). TBF = To Be Forgotten, TBR = To Be Remembered') -> RateTbl

save_kable(RateTbl, 'KylesRateTable.png')

RateTbl
```


```{r}
PivotTable %>%
  group_by(subject, type, enctype) %>%
  mutate(rate = n / sum(n)) %>%
  filter(score == 'New') %>%
  select(-score) %>%
  rename(CueDuration = enctype,
         CueType = type) -> MissRates

head(MissRates)
```

```{r, warning = FALSE}
ezANOVA(data = MissRates, 
        wid = subject, 
        within = .(CueDuration, CueType), 
        between = AgeGroup, 
        dv = rate, 
        detailed = T, type = 3, return_aov = T) -> ANOVA.fit

ANOVA.fit$ANOVA %>%
  kable(caption = 'Table 1: Miss Rate ~ AgeGroup, CueType, and CueDuration ANOVA') %>%
  kable_classic(full_width = FALSE) %>%
  footnote(general = 'DFn indicates degrees of freedom numerator. DFd indicates degrees of freedom denominator. SSn indicates sum of squares numerator. SSd indicates sum of squares denominator. ges indicates generalized eta-squared.')
```

## YAs

### TBF ANOVA

```{r}
MissRates %>%
  filter(AgeGroup == 'Young') %>%
  filter(CueType == 'To Be Forgotten') -> Young.TBF.Miss.Rates
```

```{r, warning = FALSE}
polyConMat <- matrix(data = c(-1, 0, 1, 1, -2, 1), nrow = 3)
colnames(polyConMat) <- c('.Linear', '.Quadratic')
contrasts(Young.TBF.Miss.Rates$CueDuration) <- polyConMat

# TBF ANOVA
ezANOVA(data = Young.TBF.Miss.Rates,
        wid = subject,
        within = CueDuration,
        dv = n,
        detailed = T,
        return_aov = T) -> ANOVA.fit

ANOVA.fit$aov %>%
  summary(split = list(CueDuration = list(Linear = 1, Quad = 2))) %>%
  magrittr::extract2(2) %>%
  magrittr::extract2(1) %>%
  as_tibble(rownames = 'Effect') %>%
  kable(caption = 'Table 1: Miss Rates ~ Cue Duration ANOVA -- Young, TBF items only') %>%
  kable_classic() %>%
  add_indent(c(2,3)) %>%
  footnote(general = 'Df = degrees of freedom, Sum Sq = sums of squares, Mean Sq = mean square, Pr(>F) = pvalue. Indented rows correspond to orthogonal contrasts. Linear contrast coefficients = (-1, 0, 1). Quadratic contrast coefficients = (1, -2, 1).') -> Young.TBF.ANOVA.Tbl

save_kable(x = Young.TBF.ANOVA.Tbl, file = 'Table1.png')

Young.TBF.ANOVA.Tbl
```

### TBR ANOVA

```{r, warning=FALSE}
MissRates %>%
  filter(AgeGroup == 'Young') %>%
  filter(CueType == 'To Be Remembered') -> Young.TBR.Miss.Rates
```

```{r, warning=FALSE}
# Set contrasts
polyConMat <- matrix(data = c(-1, 0, 1, 1, -2, 1), nrow = 3)
colnames(polyConMat) <- c('.Linear', '.Quadratic')
contrasts(Young.TBR.Miss.Rates$CueDuration) <- polyConMat 

# TBR ANOVA
ezANOVA(data = Young.TBR.Miss.Rates, 
        wid = subject, 
        within = CueDuration, 
        dv = n, 
        return_aov = T) -> ANOVA.fit

ANOVA.fit$aov %>%
  summary() %>%
  magrittr::extract2(2) %>%
  magrittr::extract2(1) %>%
  as_tibble(rownames = 'Effect') %>%
  kable(caption = 'Table 2: Miss Rates ~ Cue Duration ANOVA-- Young, TBR items only') %>%
  kable_classic() %>%
  footnote(general = 'Df = degrees of freedom, Sum Sq = sums of squares, Mean Sq = mean square, Pr(>F) = pvalue.') -> Young.TBR.ANOVA.Tbl

save_kable(x = Young.TBR.ANOVA.Tbl, file = 'Table2.png')

Young.TBR.ANOVA.Tbl
```

## OAs

### TBF ANOVA

```{r}
MissRates %>%
  filter(AgeGroup == 'Old') %>%
  filter(CueType == 'To Be Forgotten') -> Old.TBF.Miss.Rates
```

```{r, warning = FALSE}
polyConMat <- matrix(data = c(-1, 0, 1, 1, -2, 1), nrow = 3)
colnames(polyConMat) <- c('.Linear', '.Quadratic')
contrasts(Old.TBF.Miss.Rates$CueDuration) <- polyConMat 

# TBF ANOVA
ezANOVA(data = Old.TBF.Miss.Rates,
        wid = subject,
        within = CueDuration,
        dv = n,
        detailed = T,
        return_aov = T) -> ANOVA.fit

ANOVA.fit$aov %>%
  summary(split = list(CueDuration = list(Linear = 1, Quad = 2))) %>%
  magrittr::extract2(2) %>%
  magrittr::extract2(1) %>%
  as_tibble(rownames = 'Effect') %>%
  kable(caption = 'Table 3: Miss Rates ~ Cue Duration ANOVA -- Old, TBF items only') %>%
  kable_classic() %>%
  add_indent(c(2,3)) %>%
  footnote(general = 'Df = degrees of freedom, Sum Sq = sums of squares, Mean Sq = mean square, Pr(>F) = pvalue. Indented rows correspond to orthogonal contrasts. Linear contrast coefficients = (-1, 0, 1). Quadratic contrast coefficients = (1, -2, 1).') -> Old.TBF.ANOVA.Tbl

save_kable(Old.TBF.ANOVA.Tbl, 'Table3.png')

Old.TBF.ANOVA.Tbl
```

### TBR ANOVA

```{r, warning=FALSE}
MissRates %>%
  filter(AgeGroup == 'Old') %>%
  filter(CueType == 'To Be Remembered') -> Old.TBR.Miss.Rates
```

```{r, warning=FALSE}
# set polynomial contrasts
polyConMat <- matrix(data = c(-1, 0, 1, 1, -2, 1), nrow = 3)
colnames(polyConMat) <- c('.Linear', '.Quadratic')
contrasts(Old.TBR.Miss.Rates$CueDuration) <- polyConMat 

# TBR ANOVA
ezANOVA(data = Old.TBR.Miss.Rates, 
        wid = subject, 
        within = CueDuration, 
        dv = n, 
        return_aov = T) -> ANOVA.fit

ANOVA.fit$aov %>%
  summary() %>%
  magrittr::extract2(2) %>%
  magrittr::extract2(1) %>%
  as_tibble(rownames = 'Effect') %>%
  kable(caption = 'Table 4: Miss Rates ~ Cue Duration ANOVA-- Old TBR items only') %>%
  kable_classic() %>%
  footnote(general = 'Df = degrees of freedom, Sum Sq = sums of squares, Mean Sq = mean square, Pr(>F) = pvalue.') -> Old.TBR.ANOVA.Tbl

save_kable(Old.TBR.ANOVA.Tbl, 'Table4.png')

Old.TBR.ANOVA.Tbl
```

### Joint Figure

```{r}
MissRates %>% 
  ggplot(aes(x = CueDuration, y = rate, color = CueType)) + 
  stat_summary(fun.data = mean_se, geom = 'pointrange') +
  scale_y_continuous(breaks = seq(0.3, 0.6, 0.1)) +
  facet_grid(~AgeGroup) +
  scale_color_discrete(labels = c('TBF', 'TBR'), name = 'Cue Type') +
  expand_limits(y = c(0.3, 0.6)) +
  theme_classic() +
  labs(caption = 'Points represent mean collapsed across Age Group. Bars represent +/- SEM', 
       y = 'Miss Rate', 
       x = 'Cue Duration',
       title = 'Miss Rates', 
       subtitle = 'As a function of Cue Duration and Cue Type') -> Plot

png('MissRateFig.png')
print(Plot)
dev.off()

Plot
```

